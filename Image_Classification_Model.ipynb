{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the images in augmented into a dataframe so that the model can train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(2053, 128, 128, 3)\n",
      "(2053,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.test.is_built_with_cuda())\n",
    "from keras_preprocessing.image import img_to_array\n",
    "\n",
    "def images_to_dataframe(image_path, image_dataset, image_size):\n",
    "    label_set = np.empty((0,), dtype = int)\n",
    "\n",
    "    for image in os.listdir(image_path):\n",
    "\n",
    "        label = \"\"\n",
    "        label_list = [\"bowser\", \"luigi\", \"mario\", \"pikachu\", \"sonic\"]\n",
    "\n",
    "        for name in label_list:\n",
    "            if name in image:\n",
    "                label = np.array([name])\n",
    "\n",
    "        label_set = np.append(label_set, label)\n",
    "\n",
    "        image = Image.open(image_path + image)\n",
    "        image = image.resize((image_size, image_size))\n",
    "        image_arr = img_to_array(image)\n",
    "        image_arr = image_arr.reshape(1, image_size, image_size, 3)\n",
    "        image_dataset = np.append(image_dataset, image_arr, axis = 0)\n",
    "        \n",
    "    return image_dataset, label_set\n",
    "\n",
    "    \n",
    "image_path = \"C:/Users/joshu/Python Projects/Machine Learning Projects/Web Image Classifier/augmented/\"\n",
    "image_size = 128\n",
    "image_dataset = np.empty((0, image_size, image_size, 3), dtype = int)\n",
    "image_dataset, label_set = images_to_dataframe(image_path, image_dataset, image_size)\n",
    "\n",
    "print(image_dataset.shape)\n",
    "print(label_set.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the labels so that cross entropy loss works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... '4' '4' '4']\n",
      "(2053,)\n"
     ]
    }
   ],
   "source": [
    "label_list = [\"bowser\", \"luigi\", \"mario\", \"pikachu\", \"sonic\"]\n",
    "for i in range(len(label_set)):\n",
    "    for j in range(5):\n",
    "        if label_set[i] == label_list[j]:\n",
    "            label_set[i] = j\n",
    "\n",
    "print(label_set)\n",
    "print(label_set.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Crossentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 255.0\n",
      "0.0 1.0\n",
      "(2053, 5)\n"
     ]
    }
   ],
   "source": [
    "def show_minmax(arr,num):\n",
    "    image = arr[num]\n",
    "    print(image.min(), image.max())\n",
    "\n",
    "numClasses = 5\n",
    "input_shape = (image_size, image_size, 3)\n",
    "show_minmax(image_dataset, 1)\n",
    "image_dataset = image_dataset.astype(\"float32\")\n",
    "image_dataset /= 255\n",
    "show_minmax(image_dataset, 1)\n",
    "\n",
    "label_set = keras.utils.to_categorical(label_set, numClasses)\n",
    "print(label_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1950, 128, 128, 3)\n",
      "(1950, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(image_dataset, label_set, test_size=0.05, random_state=4)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, SpatialDropout2D, AlphaDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 127, 127, 32)      416       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 126, 126, 32)      4128      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 42, 42, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 42, 42, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 41, 41, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 20, 20, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                204816    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,573\n",
      "Trainable params: 213,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 1.3141 - accuracy: 0.4165\n",
      "Epoch 2/30\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.9801 - accuracy: 0.5811\n",
      "Epoch 3/30\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.7648 - accuracy: 0.7199\n",
      "Epoch 4/30\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.5488 - accuracy: 0.8227\n",
      "Epoch 5/30\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.4331 - accuracy: 0.8699\n",
      "Epoch 6/30\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.2962 - accuracy: 0.9133\n",
      "Epoch 7/30\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1519 - accuracy: 0.9552\n",
      "Epoch 8/30\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1109 - accuracy: 0.9615\n",
      "Epoch 9/30\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.0876 - accuracy: 0.9708\n",
      "Epoch 10/30\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1233 - accuracy: 0.9532\n",
      "Epoch 11/30\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.0672 - accuracy: 0.9742\n",
      "Epoch 12/30\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.0458 - accuracy: 0.9815\n",
      "Epoch 13/30\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0333 - accuracy: 0.9854\n",
      "Epoch 14/30\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0318 - accuracy: 0.9868\n",
      "Epoch 15/30\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0275 - accuracy: 0.9868\n",
      "Epoch 16/30\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.0255 - accuracy: 0.9883\n",
      "Epoch 17/30\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0263 - accuracy: 0.9873\n",
      "Epoch 18/30\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0299 - accuracy: 0.9854\n",
      "Epoch 19/30\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.0393 - accuracy: 0.9854\n",
      "Epoch 20/30\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.0406 - accuracy: 0.9805\n",
      "Epoch 21/30\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.0532 - accuracy: 0.9752\n",
      "Epoch 22/30\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.0188 - accuracy: 0.9903\n",
      "Epoch 23/30\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.0128 - accuracy: 0.9917\n",
      "Epoch 24/30\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.0116 - accuracy: 0.9922\n",
      "Epoch 25/30\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.0134 - accuracy: 0.9922\n",
      "Epoch 26/30\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.0126 - accuracy: 0.9917\n",
      "Epoch 27/30\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.0110 - accuracy: 0.9927\n",
      "Epoch 28/30\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.0172 - accuracy: 0.9888\n",
      "Epoch 29/30\n",
      "65/65 [==============================] - 11s 176ms/step - loss: 0.0559 - accuracy: 0.9742\n",
      "Epoch 30/30\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.0205 - accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape = input_shape, filters = 32, kernel_size = (2,2), activation = \"relu\"))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (2,2), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (3,3)))\n",
    "model.add(Dropout(rate = 0.3))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (2,2), activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(rate = 0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation = \"relu\"))\n",
    "model.add(Dense(5, activation = \"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = ([\"accuracy\"]))\n",
    "model.fit(image_dataset, label_set, epochs = epochs, shuffle = True)\n",
    "model.save(\"Img_Classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95cdb06e919eab5e2c554174537356ac9b55200d1eb6f880dc25de04343a18ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
